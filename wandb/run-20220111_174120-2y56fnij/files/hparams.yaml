core:
  version: 0.0.1
  tags:
  - mytag
data:
  datamodule:
    _target_: src.pl_data.datamodule.MyDataModule
    datasets:
      train:
        _target_: src.pl_data.dataset.MyDataset
        name: Tesla_train
        path: ${oc.env:YOUR_TRAIN_DATASET_PATH}
      val:
      - _target_: src.pl_data.dataset.MyDataset
        name: Tesla_val
        path: ${oc.env:YOUR_VAL_DATASET_PATH}
      test:
      - _target_: src.pl_data.dataset.MyDataset
        name: Tesla_test
        path: ${oc.env:YOUR_TEST_DATASET_PATH}
    time: 20
    num_workers:
      train: 8
      val: 4
      test: 4
    batch_size:
      train: 32
      val: 16
      test: 16
logging:
  val_check_interval: 1.0
  tqdm_progress_bar:
    refresh_rate: 20
  wandb:
    project: DLAI-project
    entity: Caiserini
    log_model: true
    mode: online
  wandb_watch:
    log: all
    log_freq: 100
  lr_monitor:
    logging_interval: step
    log_momentum: false
model:
  _target_: src.pl_modules.model.MyModel
  n_feature: 5
  nhead: 5
  layers: 15
optim:
  optimizer:
    _target_: torch.optim.Adam
    lr: 0.001
    betas:
    - 0.9
    - 0.999
    eps: 1.0e-08
    weight_decay: 0
  use_lr_scheduler: true
  lr_scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
    T_0: 10
    T_mult: 2
    eta_min: 0
    last_epoch: -1
    verbose: true
train:
  deterministic: false
  random_seed: 42
  pl_trainer:
    fast_dev_run: false
    gpus: 1
    precision: 32
    max_steps: 10000
    accumulate_grad_batches: 1
    num_sanity_val_steps: 2
    gradient_clip_val: 10.0
  monitor_metric: val_loss
  monitor_metric_mode: min
  early_stopping:
    patience: 42
    verbose: false
  model_checkpoints:
    save_top_k: 2
    verbose: false
